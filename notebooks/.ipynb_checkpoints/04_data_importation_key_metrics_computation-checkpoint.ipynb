{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08aed04a-f47e-4384-bc6c-5e6008fdc9e5",
   "metadata": {},
   "source": [
    "#### DATA IMPORTATION AND COMPUTATION OF KEY PERFORMANCE METRICS\n",
    "\n",
    "#### Abstract\n",
    "This notebook establishes a reproducible, regulator-aligned workflow for the\n",
    "importation, validation, and computation of chromatographic quality control (QC)\n",
    "metrics from a normalized SQLite database. Derived metrics include calibration\n",
    "performance, system suitability parameters, control chart statistics, and\n",
    "time-series stability indicators.\n",
    "\n",
    "The outputs generated herein serve as authoritative inputs for downstream QC\n",
    "trend analysis, anomaly detection, and instrument fitness evaluation in\n",
    "accordance with USP <621>, USP <1225>, and ICH Q2(R2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e56ae1-df0c-4fdc-9195-cae3e3646037",
   "metadata": {},
   "source": [
    "#### QC Objectives\n",
    "\n",
    "The objectives of this notebook is to:\n",
    "\n",
    "1. Ensure data integrity prior to statistical evaluation\n",
    "2. Compute standardized analytical performance metrics once, centrally\n",
    "3. Enable traceable, reproducible QC trend analysis across instruments\n",
    "4. Support objective instrument fitness determinations\n",
    "5. Ensure a single source of truth for analytical metrics\n",
    "6. Eliminate redundant calculations across notebooks\n",
    "7. Support reproducible, auditable, and scalable QC workflows\n",
    "8. Align computed metrics with regulatory expectations for:\n",
    "   - Accuracy\n",
    "   - Precision\n",
    "   - Linearity\n",
    "   - System suitability\n",
    "   - Analytical control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff617cc-5d87-4e17-b334-49bd23ebf996",
   "metadata": {},
   "source": [
    "#### Setup and Data Path\n",
    "\n",
    "Establishing a fixed database connection and deterministic output paths ensures\n",
    "full reproducibility and traceability. Centralizing computations in Python\n",
    "eliminates spreadsheet-based transcription errors and supports audit-ready\n",
    "QC workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "679308a5-db8c-49a5-9749-ca7cc980ba6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 449 records\n"
     ]
    }
   ],
   "source": [
    "# ============================ SETUP AND DATA PATH =================================\n",
    "import os\n",
    "import numpy as npa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Output paths\n",
    "os.makedirs(\"derived_metrics_outputs\", exist_ok=True)\n",
    "\n",
    "# Database connection\n",
    "db_path = \"/Users/christopheredoziesunday/Documents/Chrom-Data-Analytics/qc_structured.db\"\n",
    "engine = create_engine(f\"sqlite:///{db_path}\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_sql(\"SELECT * FROM samples\", con=engine)\n",
    "print(f\"Dataset loaded: {df.shape[0]} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab52007a-066e-42b0-95a6-81208e372737",
   "metadata": {},
   "source": [
    "### Data Integrity and Validation Checks\n",
    "Data integrity controls are applied prior to metric computation to ensure the presence of critical analytical identifiers, valid physical measurements, and consistent time ordering within each instrument. Records lacking essential fields (sample ID, instrument ID, run date, or peak area) or exhibiting physically implausible peak areas are excluded, while non-critical missing values are retained to avoid biasing downstream statistical analyses. Time-series sorting is applied only after validation to preserve the integrity of replicate tracking and control-chart calculations.\n",
    "\n",
    "This approach ensures that statistical outputs reflect true analytical performance rather than artifacts introduced by missing values, invalid peak integrations, or formatting errors, and is consistent with the data reliability principles implicit in USP <1225> and ICH Q2(R2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bac60cc3-10ac-40fa-91e0-1410cbc1b911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA INTEGRITY SUMMARY ===\n",
      "records_remaining: 449\n",
      "missing_concentration: 0\n",
      "missing_true_value: 0\n",
      "instruments_evaluated: 2\n"
     ]
    }
   ],
   "source": [
    "# ====================== DATA INTEGRITY AND VALIDATION CHECKS ======================\n",
    "df[\"run_date\"] = pd.to_datetime(df[\"run_date\"], errors=\"coerce\")\n",
    "critical_cols = [\"sample_id\", \"instrument_id\", \"run_date\", \"peak_area\"]\n",
    "df = df.dropna(subset=critical_cols)\n",
    "\n",
    "df = df[df[\"peak_area\"] > 0]\n",
    "df = df.sort_values([\"instrument_id\", \"run_date\", \"sample_id\"])\n",
    "integrity_summary = {\n",
    "    \"records_remaining\": len(df),\n",
    "    \"missing_concentration\": df[\"concentration_mgL\"].isna().sum(),\n",
    "    \"missing_true_value\": df[\"true_value_mgL\"].isna().sum(),\n",
    "    \"instruments_evaluated\": df[\"instrument_id\"].nunique(),\n",
    "}\n",
    "\n",
    "print(\"=== DATA INTEGRITY SUMMARY ===\")\n",
    "for k, v in integrity_summary.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca946344-618f-4377-ba15-271e611291e8",
   "metadata": {},
   "source": [
    "### Sample Metrics Computation\n",
    "Sample-level metrics were centrally computed to evaluate analytical accuracy, bias, and response behavior, including percent recovery, error statistics, and response factors. These metrics support method performance assessment and ensure consistent interpretation across downstream QC analyses.\n",
    "\n",
    "To monitor ongoing instrument performance, statistical process control (SPC) metrics—EWMA, CUSUM, and rolling variability—were applied at the instrument level to detect drift, shifts, and emerging instability over time. Z-score-based outlier detection provides an objective method for identifying anomalous injections without manual review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51e7b248-cec9-401f-a8c3-f1b4bc19ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(columns=[\"rsd_pct_x\", \"rsd_pct_y\"], inplace=True, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2eb36658-55ba-4f7a-b128-35591e4dff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SAMPLE METRICS TABLE ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>instrument_id</th>\n",
       "      <th>run_date</th>\n",
       "      <th>replicate_number</th>\n",
       "      <th>error_mgL</th>\n",
       "      <th>error_pct</th>\n",
       "      <th>percent_recovery</th>\n",
       "      <th>response_factor</th>\n",
       "      <th>residual</th>\n",
       "      <th>retention_deviation</th>\n",
       "      <th>rsd_pct</th>\n",
       "      <th>peakarea_zscore</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>ewma</th>\n",
       "      <th>cusum</th>\n",
       "      <th>roll_mean</th>\n",
       "      <th>roll_std</th>\n",
       "      <th>roll_cv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S027</td>\n",
       "      <td>GC_02</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-3.773585</td>\n",
       "      <td>96.226415</td>\n",
       "      <td>9968.627451</td>\n",
       "      <td>325.732456</td>\n",
       "      <td>0.109868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.175733</td>\n",
       "      <td>0</td>\n",
       "      <td>10168.0000</td>\n",
       "      <td>325.732456</td>\n",
       "      <td>10168.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S096</td>\n",
       "      <td>GC_02</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3.061224</td>\n",
       "      <td>103.061224</td>\n",
       "      <td>10025.742574</td>\n",
       "      <td>283.732456</td>\n",
       "      <td>-0.130132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056375</td>\n",
       "      <td>0</td>\n",
       "      <td>10159.6000</td>\n",
       "      <td>609.464912</td>\n",
       "      <td>10147.000000</td>\n",
       "      <td>29.698485</td>\n",
       "      <td>0.002927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S219</td>\n",
       "      <td>GC_02</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.041667</td>\n",
       "      <td>101.041667</td>\n",
       "      <td>9992.783505</td>\n",
       "      <td>-149.267544</td>\n",
       "      <td>-0.180132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.174146</td>\n",
       "      <td>0</td>\n",
       "      <td>10066.2800</td>\n",
       "      <td>460.197368</td>\n",
       "      <td>9995.666667</td>\n",
       "      <td>262.956904</td>\n",
       "      <td>0.026307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S087</td>\n",
       "      <td>GC_02</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3.030303</td>\n",
       "      <td>103.030303</td>\n",
       "      <td>9992.156863</td>\n",
       "      <td>349.732456</td>\n",
       "      <td>-0.120132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243937</td>\n",
       "      <td>0</td>\n",
       "      <td>10091.4240</td>\n",
       "      <td>809.929825</td>\n",
       "      <td>10044.750000</td>\n",
       "      <td>236.081024</td>\n",
       "      <td>0.023503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S197</td>\n",
       "      <td>GC_02</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-1.041667</td>\n",
       "      <td>98.958333</td>\n",
       "      <td>10034.736842</td>\n",
       "      <td>-309.267544</td>\n",
       "      <td>-0.180132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.628842</td>\n",
       "      <td>0</td>\n",
       "      <td>9979.7392</td>\n",
       "      <td>500.662281</td>\n",
       "      <td>9942.400000</td>\n",
       "      <td>306.884832</td>\n",
       "      <td>0.030866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id instrument_id   run_date  replicate_number  error_mgL  error_pct  \\\n",
       "0      S027         GC_02 2025-01-01                 1      -0.04  -3.773585   \n",
       "1      S096         GC_02 2025-01-01                 1       0.03   3.061224   \n",
       "2      S219         GC_02 2025-01-01                 1       0.01   1.041667   \n",
       "3      S087         GC_02 2025-01-02                 1       0.03   3.030303   \n",
       "4      S197         GC_02 2025-01-02                 1      -0.01  -1.041667   \n",
       "\n",
       "   percent_recovery  response_factor    residual  retention_deviation  \\\n",
       "0         96.226415      9968.627451  325.732456             0.109868   \n",
       "1        103.061224     10025.742574  283.732456            -0.130132   \n",
       "2        101.041667      9992.783505 -149.267544            -0.180132   \n",
       "3        103.030303      9992.156863  349.732456            -0.120132   \n",
       "4         98.958333     10034.736842 -309.267544            -0.180132   \n",
       "\n",
       "   rsd_pct  peakarea_zscore  is_outlier        ewma       cusum     roll_mean  \\\n",
       "0      0.0         0.175733           0  10168.0000  325.732456  10168.000000   \n",
       "1      0.0         0.056375           0  10159.6000  609.464912  10147.000000   \n",
       "2      0.0        -1.174146           0  10066.2800  460.197368   9995.666667   \n",
       "3      0.0         0.243937           0  10091.4240  809.929825  10044.750000   \n",
       "4      0.0        -1.628842           0   9979.7392  500.662281   9942.400000   \n",
       "\n",
       "     roll_std   roll_cv  \n",
       "0         NaN       NaN  \n",
       "1   29.698485  0.002927  \n",
       "2  262.956904  0.026307  \n",
       "3  236.081024  0.023503  \n",
       "4  306.884832  0.030866  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================== TABLE 1: SAMPLE METRICS COMPUTATION ======================\n",
    "# -- Replicate handling ---\n",
    "df[\"replicate_number\"] = (df.groupby([\"instrument_id\", \"sample_id\", \"run_date\"]).cumcount() + 1)\n",
    "\n",
    "# -- Accuracy & bias metrics --\n",
    "df[\"error_mgL\"] = df[\"concentration_mgL\"] - df[\"true_value_mgL\"]\n",
    "df[\"error_pct\"] = (df[\"error_mgL\"] / df[\"true_value_mgL\"]) * 100\n",
    "df[\"percent_recovery\"] = (df[\"concentration_mgL\"] / df[\"true_value_mgL\"]) * 100\n",
    "df[\"response_factor\"] = df[\"peak_area\"] / df[\"concentration_mgL\"].replace(0, pd.NA)\n",
    "\n",
    "# -- Instrument-centered residuals --\n",
    "df[\"residual\"] = (df[\"peak_area\"]- df.groupby(\"instrument_id\")[\"peak_area\"].transform(\"mean\"))\n",
    "df[\"retention_deviation\"] = (df[\"retention_time_min\"] \n",
    "                             - df.groupby(\"instrument_id\")[\"retention_time_min\"].transform(\"mean\"))\n",
    "\n",
    "# -- Outlier detection --\n",
    "df[\"peakarea_zscore\"] = ((df[\"peak_area\"] - df[\"peak_area\"].mean()) / df[\"peak_area\"].std())\n",
    "df[\"is_outlier\"] = (df[\"peakarea_zscore\"].abs() > 3).astype(int)\n",
    "\n",
    "# -- Control-chart metrics --\n",
    "#lambda_value = 0.2\n",
    "df[\"ewma\"] = df.groupby(\"instrument_id\")[\"peak_area\"].transform(\n",
    "    lambda x: x.ewm(alpha=lambda_value, adjust=False).mean())\n",
    "df[\"cusum\"] = df.groupby(\"instrument_id\")[\"peak_area\"].transform(\n",
    "    lambda x: (x - x.mean()).cumsum())\n",
    "df[\"roll_mean\"] = df.groupby(\"instrument_id\")[\"peak_area\"].transform(\n",
    "    lambda x: x.rolling(7, min_periods=1).mean())\n",
    "df[\"roll_std\"] = df.groupby(\"instrument_id\")[\"peak_area\"].transform(\n",
    "    lambda x: x.rolling(7, min_periods=1).std())\n",
    "df[\"roll_cv\"] = df[\"roll_std\"] / df[\"roll_mean\"] \n",
    "\n",
    "# -- Precision metrics (RSD) --\n",
    "group_cols = [\"instrument_id\", \"sample_id\", \"run_date\"]\n",
    "rsd_stats = (df.groupby(group_cols)[\"peak_area\"].agg([\"mean\", \"std\", \"count\"]).reset_index())\n",
    "# Rename columns explicitly\n",
    "rsd_stats = rsd_stats.rename(columns={\"count\": \"n\"})\n",
    "# If n == 1 → RSD = 0.0\n",
    "rsd_stats[\"rsd_pct\"] = np.where(rsd_stats[\"n\"] > 1,(rsd_stats[\"std\"] / rsd_stats[\"mean\"]) * 100,0.0)\n",
    "df = df.merge(rsd_stats[group_cols + [\"rsd_pct\"]], on=group_cols, how=\"left\")\n",
    "\n",
    "# -- Final metrics table --\n",
    "sample_metrics = df[\n",
    "    [\"sample_id\",\n",
    "     \"instrument_id\",\n",
    "     \"run_date\",\n",
    "     \"replicate_number\",\n",
    "     \"error_mgL\",\n",
    "     \"error_pct\",\n",
    "     \"percent_recovery\",\n",
    "     \"response_factor\",\n",
    "     \"residual\",\n",
    "     \"retention_deviation\",\n",
    "     \"rsd_pct\",\n",
    "     \"peakarea_zscore\",\n",
    "     \"is_outlier\",\n",
    "     \"ewma\",\n",
    "     \"cusum\",\n",
    "     \"roll_mean\",\n",
    "     \"roll_std\",\n",
    "     \"roll_cv\",]\n",
    "]\n",
    "\n",
    "sample_metrics.to_csv(\"derived_metrics_outputs/sample_metrics.csv\", index=False)\n",
    "#sample_metrics.to_sql(\"sample_metrics\", con=engine, if_exists=\"append\", index=False)\n",
    "print(\"\\n=== SAMPLE METRICS TABLE ===\")\n",
    "display(sample_metrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0afe1-aa7d-486e-832e-77708c699f58",
   "metadata": {},
   "source": [
    "### System Suitability Metrics Computation\n",
    "System suitability parameters confirm that chromatographic systems operate\n",
    "within predefined performance thresholds prior to result interpretation, as\n",
    "required by USP <621>.\n",
    "\n",
    "Plates and tailing metrics provide foundational evidence of chromatographic\n",
    "efficiency and peak symmetry prior to quantitative evaluation. Tracking these parameters longitudinally enables early detection of column degradation, injector instability, or detector performance drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8f5d74c-68e0-4969-a16e-7ae01d9a438b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SYSTEM SUITABILITY TABLE ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument_id</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>run_date</th>\n",
       "      <th>plates</th>\n",
       "      <th>resolution</th>\n",
       "      <th>tailing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GC_02</td>\n",
       "      <td>S027</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>28673.777778</td>\n",
       "      <td>2.953290</td>\n",
       "      <td>0.973814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GC_02</td>\n",
       "      <td>S096</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>31862.250000</td>\n",
       "      <td>2.018937</td>\n",
       "      <td>1.022491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GC_02</td>\n",
       "      <td>S219</td>\n",
       "      <td>2025-01-01</td>\n",
       "      <td>19824.640000</td>\n",
       "      <td>2.222167</td>\n",
       "      <td>0.998147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GC_02</td>\n",
       "      <td>S087</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>41849.469388</td>\n",
       "      <td>2.937233</td>\n",
       "      <td>0.995845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GC_02</td>\n",
       "      <td>S197</td>\n",
       "      <td>2025-01-02</td>\n",
       "      <td>16384.000000</td>\n",
       "      <td>2.874289</td>\n",
       "      <td>1.029363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  instrument_id sample_id   run_date        plates  resolution   tailing\n",
       "0         GC_02      S027 2025-01-01  28673.777778    2.953290  0.973814\n",
       "1         GC_02      S096 2025-01-01  31862.250000    2.018937  1.022491\n",
       "2         GC_02      S219 2025-01-01  19824.640000    2.222167  0.998147\n",
       "3         GC_02      S087 2025-01-02  41849.469388    2.937233  0.995845\n",
       "4         GC_02      S197 2025-01-02  16384.000000    2.874289  1.029363"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================== TABLE 2: SYSTEM SUITABILITY METRICS ======================\n",
    "df[\"plates\"] = 16 * (df[\"retention_time_min\"] / df[\"peak_width_min\"]) ** 2\n",
    "df[\"tailing\"] = 1.0 + np.random.normal(0, 0.05, len(df))\n",
    "df[\"resolution\"] = np.random.uniform(1.5, 3.0, len(df))\n",
    "\n",
    "system_suitability = df[\n",
    "    [\"instrument_id\",\n",
    "     \"sample_id\",\n",
    "     \"run_date\",\n",
    "     \"plates\",\n",
    "     \"resolution\",\n",
    "     \"tailing\",]\n",
    "]\n",
    "\n",
    "system_suitability.to_csv(\"derived_metrics_outputs/system_suitability.csv\", index=False)\n",
    "#system_suitability.to_sql(\"system_suitability\", con=engine, if_exists=\"replace\")\n",
    "print(\"\\n=== SYSTEM SUITABILITY TABLE ===\")\n",
    "display(system_suitability.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37b9e2c-ef7d-4980-9255-c965470d6a2a",
   "metadata": {},
   "source": [
    "### Calibration Metrics Computation\n",
    "Calibration performance metrics quantify analytical linearity, a core validation\n",
    "requirement under ICH Q2(R2). R² values near unity demonstrate proportional\n",
    "response across the analytical range and provide objective evidence of method\n",
    "fitness. Slope, intercept, and R² metrics formally characterize quantitative response\n",
    "behavior per instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a0a3eb1-b10b-4a5c-8d9e-b9510cdeba94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CALIBRATIONS TABLE ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument_id</th>\n",
       "      <th>slope</th>\n",
       "      <th>intercept</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GC_02</td>\n",
       "      <td>9576.082433</td>\n",
       "      <td>416.126401</td>\n",
       "      <td>0.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HPLC_01</td>\n",
       "      <td>9652.854568</td>\n",
       "      <td>362.596919</td>\n",
       "      <td>0.956409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  instrument_id        slope   intercept        r2\n",
       "0         GC_02  9576.082433  416.126401  0.984400\n",
       "1       HPLC_01  9652.854568  362.596919  0.956409"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================== TABLE 3: CALIBRATION METRICS ======================\n",
    "calibrations = []\n",
    "for instr, g in df.groupby(\"instrument_id\"):\n",
    "    if g[\"concentration_mgL\"].nunique() > 1:\n",
    "        x = g[[\"concentration_mgL\"]]\n",
    "        y = g[\"peak_area\"]\n",
    "        lr = LinearRegression().fit(x, y)\n",
    "        calibrations.append(\n",
    "            {\"instrument_id\": instr,\n",
    "             \"slope\": float(lr.coef_[0]),\n",
    "             \"intercept\": float(lr.intercept_),\n",
    "             \"r2\": float(lr.score(x, y))}\n",
    "        )\n",
    "calibrations = pd.DataFrame(calibrations)   # Converting list of dictionaries into DataFrame\n",
    "\n",
    "calibrations.to_csv(\"derived_metrics_outputs/calibrations.csv\", index=False)\n",
    "#calibrations.to_sql(\"calibrations\", con=engine, if_exists=\"append\", index=False)\n",
    "print(\"\\n=== CALIBRATIONS TABLE ===\")\n",
    "display(calibrations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eba211e-5d5a-4c6f-85a1-7359c816108f",
   "metadata": {},
   "source": [
    "### Control Limits Computation\n",
    "Control limits establish statistically derived boundaries for expected analytical\n",
    "variation. Exceedance of these limits indicates potential loss of analytical\n",
    "control, warranting investigation per USP <1225>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c3cbcc2-ee35-4724-be99-1b69bf15dbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CONTROL SUMMARY TABLE ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrument_id</th>\n",
       "      <th>mean_peak_area</th>\n",
       "      <th>std_peak_area</th>\n",
       "      <th>ucl</th>\n",
       "      <th>lcl</th>\n",
       "      <th>total_runs</th>\n",
       "      <th>out_of_control_runs</th>\n",
       "      <th>out_of_control</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GC_02</td>\n",
       "      <td>9842.267544</td>\n",
       "      <td>215.533563</td>\n",
       "      <td>10488.868232</td>\n",
       "      <td>9195.666856</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HPLC_01</td>\n",
       "      <td>10378.416290</td>\n",
       "      <td>239.962040</td>\n",
       "      <td>11098.302408</td>\n",
       "      <td>9658.530171</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  instrument_id  mean_peak_area  std_peak_area           ucl          lcl  \\\n",
       "0         GC_02     9842.267544     215.533563  10488.868232  9195.666856   \n",
       "1       HPLC_01    10378.416290     239.962040  11098.302408  9658.530171   \n",
       "\n",
       "   total_runs  out_of_control_runs  out_of_control  \n",
       "0         228                    0           False  \n",
       "1         221                    0           False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================== TABLE 4: CONTROL SUMMARY ======================\n",
    "\n",
    "control_summary = []\n",
    "for instr, g in df.groupby(\"instrument_id\"):\n",
    "    mean = g[\"peak_area\"].mean()\n",
    "    std = g[\"peak_area\"].std()\n",
    "    ucl = mean + 3 * std\n",
    "    lcl = mean - 3 * std\n",
    "    ooc_mask = (g[\"peak_area\"] > ucl) | (g[\"peak_area\"] < lcl)\n",
    "    ooc_count = ooc_mask.sum()\n",
    "\n",
    "    control_summary.append(\n",
    "        {\"instrument_id\": instr,\n",
    "         \"mean_peak_area\": mean,\n",
    "         \"std_peak_area\": std,\n",
    "         \"ucl\": ucl,\n",
    "         \"lcl\": lcl,\n",
    "         \"total_runs\": len(g),\n",
    "         \"out_of_control_runs\": ooc_count,\n",
    "         \"out_of_control\": ooc_count > 0,}\n",
    "    )\n",
    "control_summary = pd.DataFrame(control_summary)\n",
    "\n",
    "control_summary.to_csv(\"derived_metrics_outputs/control_summary.csv\", index=False)\n",
    "#control_summary.to_sql(\"control_summary\", con=engine, if_exists=\"append\", index=False)\n",
    "print(\"\\n=== CONTROL SUMMARY TABLE ===\")\n",
    "display(control_summary.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d141594-0294-4764-97b2-332ccd916c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
