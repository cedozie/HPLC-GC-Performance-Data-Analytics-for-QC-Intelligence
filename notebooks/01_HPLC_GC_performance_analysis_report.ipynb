{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "395f32f2-1df8-4198-877c-9ca9821159c6",
   "metadata": {},
   "source": [
    "### HPLC/GC Performance Data Analytics for Quality Control Intelligence \n",
    "**Author:** Christopher Edozie Sunday     \n",
    "**Tools Used:** Excel, SQL (SQLite), Python, Jupyter Notebook, Tableau  & Power BI \n",
    "**Domain:** Analytical Chemistry / Data Analytics  \n",
    "**Date:** 31 st December 2025 \n",
    "\n",
    "---\n",
    "#### Project Description\n",
    "This project demonstrates an end-to-end data analytics project that analyzes data from HPLC and GC instruments using Excel, SQL, Python, Tableau, and Power BI. It demonstrates data cleaning, relational database modeling, statistical QC, anomaly detection, time-series analysis, culminating in interactive dashboards for monitoring calibration performance and instrument health.\n",
    "\n",
    "#### Project Overview\n",
    "This project demonstrates analytics workflow that transforms laboratory-generated performance data from HPLC and GC instruments into actionable quality intelligence, enabling early detection of the instrument drift, calibration instability, and process anomalies before they compromise results. It bridges the gap between raw chromatographic outputs and decision-ready insights, allowing scientists, quality professionals, and supervisors to proactively monitor instrument performance, method stability, and analytical reliability.\n",
    "\n",
    "#### Project Relevance to Quality Control Scientist and Quality Intelligence Roles\n",
    "This project is designed to reflect real-world laboratory operations in manufacturing quality control, mining assay laboratories, and research facilities where data integrity, reproducibility, and timely interpretation of results are critical. This demonstrates actual responsibilities of QC Scientists, Analytical Chemists, QC Managers, Lab Supervisors, and Data Analysis Teams that works in regulated environments, including:\n",
    "\n",
    "- Trending of chromatographic performance data for compliance monitoring\n",
    "- Identification of early warning signals prior to specification failure\n",
    "- Support of deviation investigations through data-driven evidence\n",
    "- Instrument performance monitoring and method lifecycle management\n",
    "- Translation of raw analytical data into actionable quality intelligence\n",
    "\n",
    "The workflow mirrors industry practice by integrating Excel-based laboratory data, SQL-driven data structuring, and Python-based statistical analysis to support regulatory-compliant quality decisions.\n",
    "\n",
    "#### Scientific & Quality Context of this Project\n",
    "Chromatographic data is foundational to analytical decision-making, yet it is often siloed within instrument software, inconsistently structured, and underutilized for trend-based quality monitoring. Across regulated and non-regulated environments, laboratories face common challenges:\n",
    "\n",
    "- Instrument drift and performance variability\n",
    "- Delayed detection of analytical anomalies\n",
    "- Fragmented data across instruments and runs\n",
    "- Limited visibility into long-term trends\n",
    "\n",
    "In pharmaceutical and mining laboratories, these issues directly impact compliance, throughput, and risk management. In academic or research settings, they affect data reliability, reproducibility, and research validity. This project addresses these challenges through structured data modeling and statistical analysis.\n",
    "\n",
    "#### Quality & Compliance Relevance\n",
    "This project applies data analytics to chromatographic quality control within a regulated laboratory framework. Analytical performance metrics are evaluated using principles consistent with:\n",
    "\n",
    "- ICH Q2(R2): Validation of Analytical Procedures\n",
    "- ICH Q14: Analytical Procedure Development\n",
    "- FDA and EMA expectations for ongoing performance verification\n",
    "- ISO/IEC 17025 requirements for method control and monitoring\n",
    "\n",
    "Key quality objectives addressed include:\n",
    "- System suitability trending and early detection of performance drift\n",
    "- Instrument equivalency and data comparability\n",
    "- Method precision, accuracy, and robustness assessment\n",
    "- Proactive identification of risks leading to OOS or OOT results\n",
    "\n",
    "The analytical insights generated support deviation prevention, CAPA prioritization, and data-driven decision-making in QC and analytical development environments.\n",
    "\n",
    "#### Primary Project Goal:\n",
    "Enable data-driven quality decisions by converting data from chromatographic instruments into clear, traceable, and regulator-aligned performance insights.\n",
    "\n",
    "#### Project Objectives\n",
    "- Clean and convert raw HPLC/GC data into structured, analysis-ready datasets\n",
    "- Design a 3NF relational schema suitable for chromatographic quality control data\n",
    "- Implement foreign keys and indexing, and demonstrate SQL joins\n",
    "- Compute accuracy, precision, calibration, and system suitability metrics\n",
    "- Monitor instrument and method performance over time\n",
    "- Detect instrument drift early, anomalies, and out-of-control conditions\n",
    "- Produce audit-ready and reproducible end-to-end analytics workflow in JupyterLab (DDL + queries)\n",
    "- Produce narrative-driven Jupyter Notebooks explaining analytical intent and methodology\n",
    "- Scientific visualization in Python for QC interpretation and decision support\n",
    "- Build interactive Tableau dashboards for performance monitoring\n",
    "- Generate KPI-driven report in Power BI for management and quality review\n",
    "- Bridge analytical chemistry and data analytics\n",
    "\n",
    "#### Scope of Work:\n",
    "This project delivers a complete, reproducible analytics pipeline that:\n",
    "\n",
    "- Simulates realistic chromatographic QC datasets\n",
    "- Structures data into a normalized relational database\n",
    "- Computes regulatory-aligned QC metrics\n",
    "- Applies statistical quality control (SQC) and trend analytics\n",
    "- Visualizes results in interactive dashboards for decision-makers\n",
    "\n",
    "### Tools & Technologies\n",
    "- Excel → Data simulation, initial data profiling, and validation\n",
    "- SQLite + SQL (DBeaver) → Data modeling, normalization, querying\n",
    "- Python (Pandas, NumPy, Scikit-Learn) → QC metrics, SQC, trend analysis\n",
    "- Tableau → Interactive dashboards for QC monitoring and reporting\n",
    "- Power BI → KPI-driven reporting for management and quality review \n",
    "\n",
    "**This report will be divided into sections corresponding to phases of the data analysis life cycle - Ask, Prepare, Process, Analyse, Share, and Act.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4f8fe-f708-45d3-9cdd-f5bf101bec80",
   "metadata": {},
   "source": [
    "#### ASK PHASE — Defining the Problem\n",
    "**Problem Statement**\n",
    "\n",
    "Laboratory QC data is often:\n",
    "- Locked inside vendor software\n",
    "- Reviewed manually and retrospectively\n",
    "- Poorly structured for trend analysis\n",
    "\n",
    "This limits early detection of:\n",
    "- Calibration drift\n",
    "- Instrument instability\n",
    "- Method performance degradation\n",
    "\n",
    "**Key Business Questions Addressed**\n",
    "\n",
    "- Are HPLC/GC instruments operating consistently over time?\n",
    "- Are calibration models stable and linear?\n",
    "- Can early warning signals detect drift before failure?\n",
    "- How can QC data be summarized clearly for decision-makers?\n",
    "\n",
    "\n",
    "#### PREPARE PHASE — Data Sources & Rationale\n",
    "**Data Source Description:**\n",
    "\n",
    "Because real chromatographic QC data is often proprietary, this project uses a Excel-simulated but analytically realistic dataset designed to closely reflectreal HPLC/GC laboratory outputs while ensuring reproducibility and avoiding proprietary or confidential data exposure.\n",
    "Key variables include:\n",
    "\n",
    "    | Variables           | Purpose                                             |\n",
    "    |---------------------|-----------------------------------------------------|\n",
    "    | Sample_ID           | Unique identifier for each QC injection             |\n",
    "    | Instrument_ID       | Differentiates HPLC vs GC systems                   |\n",
    "    | RetentionTime_min   | Indicates chromatographic stability                 |\n",
    "    | Peak_Area           | Primary quantitative detector response              |\n",
    "    | PeakWidth_min       | Reflects column efficiency and system dispersion    |\n",
    "    | Concentration_mgL   | Calculated analyte concentration                    |\n",
    "    | TrueValue_mgL       | Reference value for accuracy assessment             |\n",
    "    | Run_Date            | Enables time-based trend analysis                   |\n",
    "\n",
    "The Excel-simulation steps are detailed in `notebooks/02_data_simulation.ipynb`, and the raw dataset saved as:\n",
    "hplc_gc_qc_data_raw.xlsx\n",
    "\n",
    "\n",
    "#### PROCESS PHASE — Cleaning & Structuring\n",
    "Data Cleaning & Validation (Excel)\n",
    "\n",
    "**Why This Matters:**\n",
    "\n",
    "QC statistics are only meaningful if the underlying data is valid.\n",
    "\n",
    "**Key Checks Performed:**\n",
    "\n",
    "- Missing values detection\n",
    "- Outlier screening (not blind removal)\n",
    "- Date standardization for time-series analysis\n",
    "\n",
    "The Cleaning & Validation (Excel) steps are detailed in `notebooks/02_data_simulation.ipynb`, and the cleaned dataset saved as:\n",
    "hplc_gc_qc_data_cleaned.xlsx\n",
    "\n",
    "This file serves as the single source of truth for all downstream analysis.\n",
    "\n",
    "**SQL Data Modeling & Normalization**\n",
    "\n",
    "A fully normalized SQLite schema (3NF) was designed to emulate real laboratory data infrastructure.\n",
    "SQL Data Modeling & Normalization steps in DBeaver are detailed in `notebooks/03_SQL_database_relational_schema_creation.ipynb`, and the core tables are:\n",
    "\n",
    "**Core Tables:**\n",
    "- instruments\n",
    "- samples\n",
    "- sample_metrics\n",
    "- calibrations\n",
    "- system_suitability\n",
    "- control_summary\n",
    "\n",
    "**Why This Matters:**\n",
    "- Eliminates redundancy\n",
    "- Enables traceability\n",
    "- Supports mant-to-one relationship\n",
    "- Supports robust and scalable QC analytics\n",
    "\n",
    "\n",
    "#### ANALYZE PHASE — Statistical & QC Analytics\n",
    "**Python-Driven QC Analytics**\n",
    "Using Pandas, NumPy, and Scikit-Learn, the project computes the following:\n",
    "\n",
    "**(a) Sample-Level Metrics**\n",
    "- Error (mg/L, %)\n",
    "- Percent recovery\n",
    "- Response factor\n",
    "- Z-score outlier detection\n",
    "- %RSD (precision)\n",
    "\n",
    "**(b) Calibration Analytics**\n",
    "- Slope, intercept, R²\n",
    "- Response factor stability\n",
    "- Linearity assessment\n",
    "\n",
    "**(c) Statistical Process Control**\n",
    "- Shewhart limits\n",
    "- EWMA charts\n",
    "- CUSUM charts\n",
    "- Rolling mean, std, CV\n",
    "\n",
    "**(d) System Suitability**\n",
    "- Plate count\n",
    "- Resolution\n",
    "- Tailing factor\n",
    "\n",
    "Detailed Python code blocks for these statistical and analytical computations are shown in  \n",
    "`notebooks/04_data_importation_key_metrics_computation.ipynb`. These analyses align conceptually with USP <621>, USP <1225>, and ICH Q2(R2) expectations.\n",
    "\n",
    "**Key Analysis Categories:**\n",
    "- Calibration Trend & Stability\n",
    "- Method Performance (Accuracy & Precision)\n",
    "- QC & Anomaly Detection\n",
    "- Instrument & System Suitability\n",
    "\n",
    "Detailed steps for each of the Analysis Categories are respectively shown in: \n",
    "- `notebooks/05_calibration_trend_analysis.ipynb`\n",
    "- `notebooks/06_method_performance_analysis.ipynb`\n",
    "- `notebooks/07_qc_anomaly_analysis.ipynb`\n",
    "- `notebooks/08_system_suitabilty_analysis.ipynb`\n",
    "\n",
    "\n",
    "#### SHARE PHASE — Visualization & Communication\n",
    "**Tableau Dashboards**\n",
    "\n",
    "**Dashboard 1 — Calibration Performance Overview**\n",
    "- Parity plots\n",
    "- Accuracy heatmaps\n",
    "- Response factor trends\n",
    "- R² linearity indicators\n",
    "\n",
    "**Dashboard 2 — Instrument Health Monitoring**\n",
    "- Peak area control charts\n",
    "- EWMA & CUSUM charts\n",
    "- Rolling statistics\n",
    "\n",
    "**Dashboard 3 — Method Performance**\n",
    "- Precision distributions\n",
    "- Accuracy (%Recovery)\n",
    "- Outlier detection maps\n",
    "\n",
    "**Audience Considerations**\n",
    "| Audience        | Needs                          |\n",
    "| --------------- | ------------------------------ |\n",
    "| QC Managers     | Stability & compliance signals |\n",
    "| Lab Supervisors | Instrument health indicators   |\n",
    "| Data Teams      | Reproducibility & structure    |\n",
    "| Recruiters      | Tool proficiency & clarity     |\n",
    "\n",
    "\n",
    "#### ACT PHASE — Insights & Recommendations\n",
    "#### Insight-Driven Analysis Report\n",
    "\n",
    "**(a) Peak Area Trend**  \n",
    "**Data-driven insight:** Peak area trends remain statistically controlled across instruments, with isolated >±3σ excursions detected over time.  \n",
    "**Risk:** Potential loss of quantitative accuracy due to intermittent injector, detector, or sample preparation variability, increasing OOS risk.  \n",
    "**Actionable recommendation:** Initiate targeted deviation review, verify system suitability, and trend instrument performance per ICH Q2/Q14 and ISO 17025.\n",
    "\n",
    "\n",
    "**(b) EWMA Chart** \n",
    "**Data-driven insight:** EWMA trends show gradual peak area shifts approaching control limits across sequential runs, indicating low-level systematic drift not evident in individual results.  \n",
    "**Risk:** Early method bias may progress to OOS or compromised quantitation if unaddressed.  \n",
    "**Actionable recommendation:** Enhance trending review, verify system suitability parameters, and perform proactive instrument maintenance per ICH Q2/Q14 expectations.\n",
    "\n",
    "\n",
    "**(c) CUSUM Chart**  \n",
    "**Data-driven insight:** CUSUM charts demonstrate sustained cumulative deviation from the historical mean across sequential runs, indicating persistent low-magnitude bias not captured by Shewhart limits.  \n",
    "**Risk:** Undetected systematic drift may compromise long-term method accuracy and lead to delayed OOS findings.  \n",
    "**Actionable recommendation:** Trigger trend-based investigation, reassess method control strategy, and implement preventive maintenance per ICH Q14 and ISO 17025.\n",
    "\n",
    "\n",
    "**(d) Rolling Statistics**  \n",
    "**Data-driven insight:** Rolling mean and variability metrics show gradual increases over time, indicating emerging instability in quantitative response across sequential runs.  \n",
    "**Risk:** Progressive loss of method precision and robustness, increasing likelihood of OOS or invalid trend conclusions.  \n",
    "**Actionable recommendation:**  Strengthen ongoing performance monitoring, review maintenance and consumables, and reassess control limits per ICH Q2/Q14 and ISO 17025 expectations.\n",
    "\n",
    "\n",
    "**(e) Parity Plot**  \n",
    "**Data-driven insight:** Parity plots show strong linear agreement with the 1:1 line across instruments, with minor dispersion at higher concentrations, indicating generally acceptable calibration accuracy.  \n",
    "**Risk:** Emerging bias at range extremes may impact quantitation accuracy and reportable results.  \n",
    "**Actionable recommendation:** Review calibration model fit and range suitability, verify r² and recovery against acceptance criteria, and update calibration strategy per ICH Q2/Q14 and ISO 17025.\n",
    "\n",
    "\n",
    "**(f) Accuracy Heatmap**  \n",
    "**Data-driven insight:** Mean percent recovery remains largely centered around 100% across instruments and months, with localized periods approaching acceptance limits, indicating emerging temporal variability.  \n",
    "**Risk:** Sustained recovery drift may compromise method accuracy and reportable results, increasing OOS risk.  \n",
    "**Actionable recommendation:** Implement enhanced accuracy trending, review calibration and sample preparation practices, and initiate preventive CAPA per ICH Q2/Q14 and ISO 17025.\n",
    "\n",
    "\n",
    "**(g) Response Factor Stability**  \n",
    "**Data-driven insight:** Response factor trends remain largely stable, with intermittent approaches to ±2σ Westgard limits across instruments, indicating early-stage analytical variability.  \n",
    "**Risk:** Continued drift may degrade calibration integrity and quantitative accuracy, increasing OOS risk.  \n",
    "**Actionable recommendation:** Apply Westgard rule evaluation, review calibration preparation and detector performance, and initiate preventive maintenance and trending per FDA, ICH Q2/Q14, and ISO 17025.\n",
    "\n",
    "\n",
    "**(h) Calibration Linearity (R²)**  \n",
    "**Data-driven insight:** Calibration linearity (R²) meets predefined acceptance criteria across instruments, demonstrating adequate method linearity and model fit.  \n",
    "**Risk:** Marginal proximity to the acceptance threshold may reduce sensitivity to emerging non-linearity over time.  \n",
    "**Actionable recommendation:** Maintain periodic linearity verification, expand calibration range review, and trend R² results per ICH Q2/Q14 and ISO 17025 to ensure sustained method validity.\n",
    "\n",
    "\n",
    "**(i) Precision (RSD Distribution)**  \n",
    "**Data-driven insight:** %RSD distributions are predominantly within typical ≤5% precision criteria across instruments, with occasional higher values indicating sporadic variability.  \n",
    "**Risk:** Intermittent precision failures may compromise method repeatability and confidence in reported results.  \n",
    "**Actionable recommendation:** Investigate high-%RSD events, assess replicate handling and instrument performance, and reinforce system suitability and precision monitoring per ICH Q2/Q14 and ISO 17025.\n",
    "\n",
    "\n",
    "**(j) Accuracy Recovery**  \n",
    "**Data-driven insight:** %Recovery distributions are centered near 100% across instruments, with occasional values approaching acceptance limits, indicating generally acceptable accuracy with minor variability.  \n",
    "**Risk:** Outlier recoveries may signal calibration drift or sample preparation bias, potentially impacting reportable results.  \n",
    "**Actionable recommendation:**  Review accuracy outliers, verify calibration integrity, and reinforce routine accuracy trending and system suitability checks per ICH Q2/Q14 and ISO 17025.\n",
    "\n",
    "\n",
    "**(k) Instrument Comparison**  \n",
    "**Data-driven insight:** Measured concentration distributions are comparable across instruments, with modest inter-instrument spread, indicating generally consistent performance.  \n",
    "**Risk:** Systematic inter-instrument bias may affect data comparability and trending across platforms.  \n",
    "**Actionable recommendation:** Perform cross-instrument equivalency assessment, review calibration and standardization practices, and document instrument comparability per FDA and ISO 17025 requirements.\n",
    "\n",
    "\n",
    "**(l) Resolution Trend**  \n",
    "**Data-driven insight:** Resolution trends remain above the minimum acceptance criterion (Rs ≥ 1.5) across instruments, with localized variability observed in rolling statistics.  \n",
    "**Risk:** Progressive resolution decline may impair peak separation, increasing mis-identification and quantitation errors.  \n",
    "**Actionable recommendation:** Intensify system suitability trending, assess column condition and mobile phase performance, and initiate preventive maintenance or method adjustment per ICH Q2/Q14 and ISO 17025.\n",
    "\n",
    "\n",
    "**(m) Cpk Analysis**  \n",
    "**Data-driven insight:** Capability indices (Cpk) for resolution, tailing, plates, and retention time are generally ≥1.33, indicating adequate and stable instrument performance within defined system suitability limits.  \n",
    "**Risk:** Marginal Cpk values may reduce process robustness, increasing sensitivity to routine variability.  \n",
    "**Actionable recommendation:** Trend Cpk metrics routinely, tighten preventive maintenance and calibration schedules, and reassess suitability limits per FDA, ICH Q2/Q14, and ISO 17025.\n",
    "\n",
    "\n",
    "**(n) Plate Change Impact**  \n",
    "**Data-driven insight:** Plate count trends are largely stable for both HPLC and GC systems, with isolated ≥3σ deviations indicating abrupt efficiency changes.  \n",
    "**Risk:** Sudden plate count loss may reflect column degradation or system contamination, reducing separation efficiency and method robustness.  \n",
    "**Actionable recommendation:** Investigate flagged events per deviation procedures, assess column condition and system cleanliness, and reinforce efficiency trending and preventive maintenance in alignment with ICH Q2/Q14 and ISO 17025.\n",
    "\n",
    "\n",
    "**(o) System Suitability Heatmap**  \n",
    "**Data-driven insight:** Monthly system suitability performance is predominantly compliant across instruments, with intermittent metric-specific failures observed by period.  \n",
    "**Risk:** Recurrent localized failures may indicate emerging instrument or method instability, increasing deviation and OOS risk.  \n",
    "**Actionable recommendation:** Perform period-based root cause analysis, strengthen trending reviews, and implement targeted CAPA and preventive maintenance per FDA, ICH Q2/Q14, and ISO 17025.\n",
    "\n",
    "\n",
    "**(p) Tailing Factor Trend**  \n",
    "**Data-driven insight:** Tailing factor values remain predominantly within the established acceptance limit (TF ≤ 2), with occasional upward excursions observed across instruments.  \n",
    "**Risk:** Increased tailing may impair peak integration accuracy and quantitation reliability.  \n",
    "**Actionable recommendation:** Investigate excursions via deviation procedures, evaluate column health and system cleanliness, and reinforce routine tailing trending and preventive maintenance per ICH Q2/Q14 and ISO 17025.\n",
    "\n",
    "\n",
    "### Final Takeaway\n",
    "Analytical evaluation of HPLC and GC instruments demonstrates overall compliance with system suitability and QC criteria (RSD ≤5%, %Recovery 95–105%, resolution ≥1.5, tailing ≤2, plates ≥2000). Minor trends in retention time, plate counts, and tailing suggest early-stage column or system variability. Proactive maintenance, targeted trending, and CAPA review are recommended to sustain method robustness, prevent OOS events, and ensure ongoing GxP/regulatory compliance.\n",
    "\n",
    "This project therefore demonstrated how laboratory QC data can evolve from static records into proactive quality intelligence using accessible analytics tools. It bridges analytical chemistry and data analytics, showcasing a skill set directly relevant to modern, data-driven scientific and industrial environments.\n",
    "\n",
    "#### Expected Impact\n",
    "- Earlier detection of analytical drift\n",
    "- Reduced risk of invalid results\n",
    "- Improved regulatory defensibility\n",
    "- Faster QC decision-making\n",
    "- Demonstrates scalable analytics maturity\n",
    "\n",
    "#### Deliverables\n",
    "| Deliverable          | Description                     |\n",
    "| -------------------- | ------------------------------- |\n",
    "| Cleaned Dataset      | Excel-validated QC data         |\n",
    "| SQLite Database      | Fully normalized QC schema      |\n",
    "| Python Notebooks     | Reproducible analytics pipeline |\n",
    "| Tableau Dashboards   | Interactive QC monitoring       |\n",
    "| GitHub Documentation | End-to-end project narrative    |\n",
    "\n",
    "#### Schedule Overview\n",
    "| Phase                      | Duration |\n",
    "| -------------------------- | -------- |\n",
    "| Data Simulation & Cleaning | Week 1   |\n",
    "| SQL Modeling & Seeding     | Week 2   |\n",
    "| Python Analytics           | Week 3   |\n",
    "| Visualization & Reporting  | Week 4   |\n",
    "\n",
    "Estimated Completion: 4 weeks (part-time, revision-inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29406d-3897-4337-8d55-531670af47c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
